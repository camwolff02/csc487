{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2.2: Perceptron Algorithm in PyTorch\n",
    "\n",
    "In this lab you will again implement the perceptron algorithm, but this time using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/cam/venv/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/cam/venv/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/cam/venv/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/cam/venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/cam/venv/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/cam/venv/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/cam/venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/cam/venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/cam/venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/cam/venv/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/cam/venv/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/cam/venv/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/cam/venv/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/cam/venv/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/cam/venv/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/cam/venv/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/cam/venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/cam/venv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/cam/venv/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/cam/venv/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/cam/venv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/cam/venv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/cam/venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is very similar to NumPy in its basic functionality.  In PyTorch arrays are called tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(6)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.zeros(3,5).float()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A note on broadcasting:* You may have noticed in the previous lab that NumPy is particular about the sizes of the arrays in operations; PyTorch is the same way.\n",
    "\n",
    "For example, if `A` has shape `(10,5)` and `b` has shape `(10,)`, then we can't compute `A*b`.  It wants the *last* dimensions to match, not the first ones.  So you would need to do either `A.T*b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(10,5))\n",
    "b = np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operands could not be broadcast together with shapes (10,5) (10,) \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    A*b\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18855324,  1.28726858,  0.51256884,  0.51814703, -1.00162589,\n",
       "         0.68321507, -1.56497073,  0.87358068,  0.98523351,  0.10082051],\n",
       "       [ 0.28205935, -0.55162952,  1.18200814, -0.38159949,  0.77415902,\n",
       "         0.9491022 , -0.64211142, -0.80010773,  0.18593863,  0.69395376],\n",
       "       [ 1.11494288,  2.74076169, -0.3282237 , -0.17072238, -0.98394359,\n",
       "         0.77188869, -0.26801037,  0.04752706,  0.5715008 , -1.94777957],\n",
       "       [-0.48944808,  2.92772875,  1.61479923,  0.6851468 , -0.56832597,\n",
       "        -1.27275893, -0.37358047, -0.98451901,  1.39416489,  1.43298344],\n",
       "       [ 0.7054441 ,  0.14236854, -0.13088255, -0.88995339, -0.97969072,\n",
       "         0.34576788, -0.96749   , -1.58297491,  0.86171779, -0.47094699]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to introduce an extra dimension of size one to $b$.  However, note that this produces the transposed result from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18855324,  0.28205935,  1.11494288, -0.48944808,  0.7054441 ],\n",
       "       [ 1.28726858, -0.55162952,  2.74076169,  2.92772875,  0.14236854],\n",
       "       [ 0.51256884,  1.18200814, -0.3282237 ,  1.61479923, -0.13088255],\n",
       "       [ 0.51814703, -0.38159949, -0.17072238,  0.6851468 , -0.88995339],\n",
       "       [-1.00162589,  0.77415902, -0.98394359, -0.56832597, -0.97969072],\n",
       "       [ 0.68321507,  0.9491022 ,  0.77188869, -1.27275893,  0.34576788],\n",
       "       [-1.56497073, -0.64211142, -0.26801037, -0.37358047, -0.96749   ],\n",
       "       [ 0.87358068, -0.80010773,  0.04752706, -0.98451901, -1.58297491],\n",
       "       [ 0.98523351,  0.18593863,  0.5715008 ,  1.39416489,  0.86171779],\n",
       "       [ 0.10082051,  0.69395376, -1.94777957,  1.43298344, -0.47094699]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*b[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18855324,  0.28205935,  1.11494288, -0.48944808,  0.7054441 ],\n",
       "       [ 1.28726858, -0.55162952,  2.74076169,  2.92772875,  0.14236854],\n",
       "       [ 0.51256884,  1.18200814, -0.3282237 ,  1.61479923, -0.13088255],\n",
       "       [ 0.51814703, -0.38159949, -0.17072238,  0.6851468 , -0.88995339],\n",
       "       [-1.00162589,  0.77415902, -0.98394359, -0.56832597, -0.97969072],\n",
       "       [ 0.68321507,  0.9491022 ,  0.77188869, -1.27275893,  0.34576788],\n",
       "       [-1.56497073, -0.64211142, -0.26801037, -0.37358047, -0.96749   ],\n",
       "       [ 0.87358068, -0.80010773,  0.04752706, -0.98451901, -1.58297491],\n",
       "       [ 0.98523351,  0.18593863,  0.5715008 ,  1.39416489,  0.86171779],\n",
       "       [ 0.10082051,  0.69395376, -1.94777957,  1.43298344, -0.47094699]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*np.expand_dims(b,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, carefully check the sizes of all arrays in your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from palmerpenguins import load_penguins\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we loading and format the Palmer penguins dataset for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_penguins()\n",
    "\n",
    "# drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# tricky code to randomly shuffle the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# select only two specices\n",
    "df = df[(df['species']=='Adelie')|(df['species']=='Chinstrap')]\n",
    "\n",
    "# get two features\n",
    "X = df[['flipper_length_mm','bill_length_mm']].values\n",
    "\n",
    "# convert speces labels to -1 and 1\n",
    "y = df['species'].map({'Adelie':-1,'Chinstrap':1}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the learning algorithm work more smoothly, we we will subtract the mean of each feature.\n",
    "\n",
    "Here `np.mean` calculates a mean, and `axis=0` tells NumPy to calculate the mean over the rows (calculate the mean of each column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X -= np.mean(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our `X` and `y` arrays to torch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors moved to GPU\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y).float()\n",
    "\n",
    "# move X and y to the GPU if possible\n",
    "if torch.cuda.is_available():\n",
    "    print('tensors moved to GPU')\n",
    "    X = X.to('cuda')\n",
    "    y = y.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0794e+00,  3.1953e+00],\n",
       "        [ 2.0794e+00,  9.6953e+00],\n",
       "        [ 1.0794e+00, -4.2047e+00],\n",
       "        [-2.9206e+00, -6.1047e+00],\n",
       "        [-1.9206e+00, -2.4047e+00],\n",
       "        [-1.0921e+01, -5.5047e+00],\n",
       "        [ 3.0794e+00, -6.5047e+00],\n",
       "        [-5.9206e+00, -2.4047e+00],\n",
       "        [-5.9206e+00, -6.8047e+00],\n",
       "        [-1.9921e+01, -4.1047e+00],\n",
       "        [-3.9206e+00, -2.5047e+00],\n",
       "        [-6.9206e+00, -8.0047e+00],\n",
       "        [ 4.0794e+00,  2.0953e+00],\n",
       "        [-1.3921e+01, -8.9047e+00],\n",
       "        [ 3.0794e+00, -1.7047e+00],\n",
       "        [-7.9206e+00, -5.6047e+00],\n",
       "        [ 6.0794e+00,  8.1953e+00],\n",
       "        [ 4.0794e+00,  8.8953e+00],\n",
       "        [-3.9206e+00, -1.9047e+00],\n",
       "        [-5.9206e+00, -2.5047e+00],\n",
       "        [ 9.0794e+00,  9.3953e+00],\n",
       "        [ 1.6079e+01, -1.2047e+00],\n",
       "        [-2.9206e+00, -5.1047e+00],\n",
       "        [-1.9206e+00, -3.5047e+00],\n",
       "        [ 7.9439e-02, -4.7047e+00],\n",
       "        [-4.9206e+00, -5.3047e+00],\n",
       "        [ 7.0794e+00, -3.4047e+00],\n",
       "        [-3.9206e+00, -3.4047e+00],\n",
       "        [ 1.0794e+00, -5.2047e+00],\n",
       "        [-5.9206e+00, -3.0047e+00],\n",
       "        [-6.9206e+00,  4.9953e+00],\n",
       "        [-1.0921e+01, -3.1047e+00],\n",
       "        [-9.2056e-01,  3.1953e+00],\n",
       "        [-2.9206e+00, -9.0467e-01],\n",
       "        [-1.9206e+00, -2.7047e+00],\n",
       "        [ 1.5079e+01,  1.3795e+01],\n",
       "        [-9.2056e-01, -3.2047e+00],\n",
       "        [-6.9206e+00, -3.8047e+00],\n",
       "        [-4.9206e+00,  1.1953e+00],\n",
       "        [-9.9206e+00, -9.0467e-01],\n",
       "        [ 7.9439e-02, -4.0467e-01],\n",
       "        [ 1.0794e+00,  4.5953e+00],\n",
       "        [-1.3921e+01, -2.5047e+00],\n",
       "        [-4.9206e+00,  4.1953e+00],\n",
       "        [-1.0921e+01, -2.9047e+00],\n",
       "        [-1.0921e+01,  3.9533e-01],\n",
       "        [ 5.0794e+00,  1.1953e+00],\n",
       "        [ 9.0794e+00,  8.7953e+00],\n",
       "        [ 1.8079e+01,  8.7953e+00],\n",
       "        [ 1.8079e+01,  9.9953e+00],\n",
       "        [-1.9206e+00, -2.8047e+00],\n",
       "        [ 8.0794e+00,  7.4953e+00],\n",
       "        [ 7.9439e-02,  1.1953e+00],\n",
       "        [-1.0921e+01,  1.5995e+01],\n",
       "        [-4.9206e+00,  4.9533e-01],\n",
       "        [-4.9206e+00, -5.8047e+00],\n",
       "        [-1.1921e+01, -3.2047e+00],\n",
       "        [-2.9206e+00,  4.7953e+00],\n",
       "        [-5.9206e+00, -2.4047e+00],\n",
       "        [ 8.0794e+00, -4.6729e-03],\n",
       "        [ 1.0794e+00, -6.9047e+00],\n",
       "        [ 8.0794e+00, -1.8047e+00],\n",
       "        [-1.9206e+00, -8.5047e+00],\n",
       "        [-1.9206e+00, -2.3047e+00],\n",
       "        [ 1.0794e+00, -1.4047e+00],\n",
       "        [ 1.1079e+01,  8.6953e+00],\n",
       "        [ 8.0794e+00,  8.4953e+00],\n",
       "        [ 2.0794e+00, -4.4047e+00],\n",
       "        [ 9.0794e+00,  8.4953e+00],\n",
       "        [-1.0921e+01, -4.4047e+00],\n",
       "        [-6.9206e+00, -5.4047e+00],\n",
       "        [ 1.0794e+00,  9.2953e+00],\n",
       "        [ 7.0794e+00, -4.5047e+00],\n",
       "        [ 1.0079e+01,  8.1953e+00],\n",
       "        [-9.2056e-01, -6.4047e+00],\n",
       "        [ 4.0794e+00,  6.9533e-01],\n",
       "        [-1.7921e+01, -4.2047e+00],\n",
       "        [ 4.0794e+00,  7.9953e+00],\n",
       "        [ 5.0794e+00,  1.0953e+00],\n",
       "        [ 1.3079e+01, -9.0467e-01],\n",
       "        [-1.5921e+01, -1.8047e+00],\n",
       "        [ 6.0794e+00,  9.2953e+00],\n",
       "        [-1.9206e+00, -1.3047e+00],\n",
       "        [-1.9206e+00, -3.2047e+00],\n",
       "        [ 6.0794e+00, -3.9047e+00],\n",
       "        [ 3.0794e+00, -2.8047e+00],\n",
       "        [-4.9206e+00, -1.5047e+00],\n",
       "        [-6.9206e+00, -5.0047e+00],\n",
       "        [-1.1921e+01, -4.3047e+00],\n",
       "        [-1.9206e+00, -9.0467e-01],\n",
       "        [-4.9206e+00, -5.8047e+00],\n",
       "        [ 3.0794e+00, -6.0047e+00],\n",
       "        [ 1.0794e+00, -2.3047e+00],\n",
       "        [ 7.9439e-02, -7.0047e+00],\n",
       "        [ 3.0794e+00,  3.6953e+00],\n",
       "        [ 1.1079e+01, -1.0047e+00],\n",
       "        [-9.2056e-01, -6.0467e-01],\n",
       "        [ 4.0794e+00, -1.7047e+00],\n",
       "        [ 5.0794e+00,  1.0695e+01],\n",
       "        [-1.9206e+00,  3.8953e+00],\n",
       "        [-9.2056e-01, -3.0047e+00],\n",
       "        [-7.9206e+00, -5.4047e+00],\n",
       "        [-1.9206e+00, -4.2047e+00],\n",
       "        [ 7.0794e+00,  5.4953e+00],\n",
       "        [-1.9206e+00, -7.0047e+00],\n",
       "        [-1.1921e+01, -1.5047e+00],\n",
       "        [-4.9206e+00, -3.9047e+00],\n",
       "        [ 6.0794e+00,  7.7953e+00],\n",
       "        [ 4.0794e+00, -2.8047e+00],\n",
       "        [-4.9206e+00,  9.4953e+00],\n",
       "        [-3.9206e+00, -9.9047e+00],\n",
       "        [ 3.0794e+00,  7.9533e-01],\n",
       "        [-4.9206e+00, -6.7047e+00],\n",
       "        [-7.9206e+00, -2.3047e+00],\n",
       "        [-9.2056e-01, -2.4047e+00],\n",
       "        [-7.9206e+00, -7.6047e+00],\n",
       "        [ 5.0794e+00,  3.7953e+00],\n",
       "        [-2.9206e+00, -3.7047e+00],\n",
       "        [-9.2056e-01,  6.4953e+00],\n",
       "        [ 5.0794e+00,  9.9953e+00],\n",
       "        [-7.9206e+00, -4.8047e+00],\n",
       "        [-6.9206e+00, -6.3047e+00],\n",
       "        [ 1.0794e+00,  3.6953e+00],\n",
       "        [ 7.0794e+00, -4.7047e+00],\n",
       "        [-9.2056e-01,  4.3953e+00],\n",
       "        [-6.9206e+00, -3.0047e+00],\n",
       "        [-1.9206e+00, -6.0047e+00],\n",
       "        [-1.1921e+01,  1.9533e-01],\n",
       "        [-3.9206e+00,  3.3953e+00],\n",
       "        [-9.9206e+00, -5.5047e+00],\n",
       "        [ 9.0794e+00, -5.0467e-01],\n",
       "        [ 6.0794e+00, -4.3047e+00],\n",
       "        [-4.9206e+00, -6.0047e+00],\n",
       "        [-2.9206e+00, -7.4047e+00],\n",
       "        [ 4.0794e+00,  8.8953e+00],\n",
       "        [ 4.0794e+00,  3.4953e+00],\n",
       "        [-1.9206e+00, -3.8047e+00],\n",
       "        [-1.9206e+00,  4.3953e+00],\n",
       "        [ 7.0794e+00,  6.0953e+00],\n",
       "        [ 6.0794e+00, -7.4047e+00],\n",
       "        [-9.2056e-01, -4.7047e+00],\n",
       "        [-4.9206e+00, -5.8047e+00],\n",
       "        [ 7.9439e-02, -9.0467e-01],\n",
       "        [ 3.0794e+00,  9.5327e-02],\n",
       "        [ 9.0794e+00,  1.2195e+01],\n",
       "        [-2.9206e+00, -6.3047e+00],\n",
       "        [-1.3921e+01,  4.0953e+00],\n",
       "        [ 3.0794e+00, -7.0467e-01],\n",
       "        [-6.9206e+00, -5.0047e+00],\n",
       "        [ 9.0794e+00,  9.9953e+00],\n",
       "        [-4.9206e+00, -1.1047e+00],\n",
       "        [-1.9206e+00,  8.0953e+00],\n",
       "        [ 3.0794e+00,  4.6953e+00],\n",
       "        [-9.2056e-01,  2.9533e-01],\n",
       "        [ 2.0794e+00, -7.0467e-01],\n",
       "        [ 3.0794e+00,  7.1953e+00],\n",
       "        [ 3.0794e+00,  5.5953e+00],\n",
       "        [ 3.0794e+00,  7.6953e+00],\n",
       "        [ 5.0794e+00,  9.2953e+00],\n",
       "        [ 1.8079e+01,  2.0953e+00],\n",
       "        [ 1.1079e+01,  8.9953e+00],\n",
       "        [-4.9206e+00,  4.9533e-01],\n",
       "        [ 3.0794e+00, -3.3047e+00],\n",
       "        [ 5.0794e+00,  4.9533e-01],\n",
       "        [-1.3921e+01, -4.8047e+00],\n",
       "        [ 1.0794e+00, -4.1047e+00],\n",
       "        [ 7.9439e-02,  4.8953e+00],\n",
       "        [ 1.1079e+01,  7.2953e+00],\n",
       "        [ 4.0794e+00, -2.4047e+00],\n",
       "        [ 3.0794e+00, -5.0467e-01],\n",
       "        [ 1.3079e+01,  1.0795e+01],\n",
       "        [-1.9206e+00, -6.1047e+00],\n",
       "        [ 1.0079e+01,  1.4953e+00],\n",
       "        [-1.9206e+00, -6.5047e+00],\n",
       "        [-1.9206e+00, -3.9047e+00],\n",
       "        [ 1.8079e+01,  6.9953e+00],\n",
       "        [ 6.0794e+00, -2.0467e-01],\n",
       "        [ 7.0794e+00, -1.4047e+00],\n",
       "        [ 4.0794e+00,  8.9533e-01],\n",
       "        [ 3.0794e+00, -1.2047e+00],\n",
       "        [ 3.0794e+00, -5.6047e+00],\n",
       "        [-4.9206e+00, -7.5047e+00],\n",
       "        [-7.9206e+00, -1.1047e+00],\n",
       "        [-7.9206e+00, -2.2047e+00],\n",
       "        [ 7.9439e-02,  4.4953e+00],\n",
       "        [-1.9206e+00, -5.7047e+00],\n",
       "        [ 5.0794e+00,  8.2953e+00],\n",
       "        [ 2.0794e+00,  3.9953e+00],\n",
       "        [ 3.0794e+00,  3.9953e+00],\n",
       "        [ 1.0079e+01, -6.0467e-01],\n",
       "        [-6.9206e+00, -4.4047e+00],\n",
       "        [ 1.0079e+01, -6.3047e+00],\n",
       "        [-5.9206e+00, -6.0047e+00],\n",
       "        [-9.2056e-01,  3.5953e+00],\n",
       "        [ 1.0794e+00, -2.3047e+00],\n",
       "        [ 5.0794e+00,  1.0195e+01],\n",
       "        [-1.0921e+01, -3.9047e+00],\n",
       "        [-9.2056e-01, -1.1047e+00],\n",
       "        [ 1.3079e+01,  1.1495e+01],\n",
       "        [ 1.0794e+00,  8.5953e+00],\n",
       "        [-9.2056e-01, -3.4047e+00],\n",
       "        [-1.9206e+00, -3.1047e+00],\n",
       "        [ 2.0794e+00,  3.5953e+00],\n",
       "        [ 1.0794e+00, -5.3047e+00],\n",
       "        [ 1.0794e+00, -1.8047e+00],\n",
       "        [ 5.0794e+00,  1.9533e-01],\n",
       "        [-9.9206e+00, -9.0467e-01],\n",
       "        [ 2.0079e+01,  6.9953e+00],\n",
       "        [ 1.4079e+01,  9.8953e+00],\n",
       "        [-3.9206e+00, -9.0467e-01],\n",
       "        [-8.9206e+00, -1.4047e+00],\n",
       "        [-4.9206e+00, -1.4047e+00],\n",
       "        [ 1.0794e+00,  7.5953e+00],\n",
       "        [-8.9206e+00, -4.3047e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Your task is to again complete this class for the perceptron, with two changes from last time:\n",
    "- the implementation should use PyTorch tensors, not NumPy arrays;\n",
    "- `train_step` now accepts the entire dataset as input and should calculate the average gradient over all examples, rather than updating the weights one data point at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab_flake8 in /home/cam/venv/lib/python3.12/site-packages (0.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jupyterlab_flake8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, lr=1e-3):\n",
    "        # store the learning rate\n",
    "        self.lr = lr\n",
    "\n",
    "        # initialize the weights to small, normally-distributed values\n",
    "        self.w = torch.normal(mean=0, std=0.01, size=(2,))  # shape (2,)\n",
    "\n",
    "        # initialize the bias to zero\n",
    "        self.b = torch.zeros(1)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.w = self.w.to('cuda')\n",
    "            self.b = self.b.to('cuda')\n",
    "                \n",
    "\n",
    "    def train_step(self, X:torch.Tensor, y:torch.Tensor) -> None:\n",
    "        \"\"\" Apply the first update rule shown in lecture.\n",
    "            Arguments:\n",
    "             x: data matrix of shape (N,2)\n",
    "             y: labels of shape (N,) \n",
    "        \"\"\"\n",
    "        z = X@self.w + self.b  # shape (N,)\n",
    "        \n",
    "        self.w += self.lr * torch.mean((y - z).unsqueeze(-1) * X, dim=0)\n",
    "        self.b += self.lr * torch.mean(y - z)\n",
    "    \n",
    "    def predict(self,X:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Calculate model prediction for all data points.\n",
    "            Arguments:\n",
    "             X: data matrix of shape (N,3)   \n",
    "            Returns:\n",
    "             Predicted labels (-1 or 1) of shape (N,)\n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        z = X@self.w + self.b\n",
    "        return torch.where(z > 0, 1, -1) \n",
    "        \n",
    "    def score(self,X:torch.Tensor,y:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Calculate model accuracy\n",
    "            Arguments:\n",
    "             X: data matrix of shape (N,3)   \n",
    "             y: labels of shape (N,)\n",
    "            Returns:\n",
    "             Accuracy score\n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        return torch.mean((self.predict(X) == y).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to train the model and print out the accuracy at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: 0.84112149477005\n",
      "step 1: 0.84112149477005\n",
      "step 2: 0.84112149477005\n",
      "step 3: 0.84112149477005\n",
      "step 4: 0.84112149477005\n",
      "step 5: 0.8457943797111511\n",
      "step 6: 0.8457943797111511\n",
      "step 7: 0.8457943797111511\n",
      "step 8: 0.8504672646522522\n",
      "step 9: 0.8504672646522522\n",
      "step 10: 0.8504672646522522\n",
      "step 11: 0.8504672646522522\n",
      "step 12: 0.8551401495933533\n",
      "step 13: 0.8551401495933533\n",
      "step 14: 0.8551401495933533\n",
      "step 15: 0.8551401495933533\n",
      "step 16: 0.8551401495933533\n",
      "step 17: 0.8551401495933533\n",
      "step 18: 0.8551401495933533\n",
      "step 19: 0.8551401495933533\n",
      "step 20: 0.8551401495933533\n",
      "step 21: 0.8551401495933533\n",
      "step 22: 0.8551401495933533\n",
      "step 23: 0.8598130345344543\n",
      "step 24: 0.8598130345344543\n",
      "step 25: 0.8598130345344543\n",
      "step 26: 0.8644859790802002\n",
      "step 27: 0.8644859790802002\n",
      "step 28: 0.8644859790802002\n",
      "step 29: 0.8644859790802002\n",
      "step 30: 0.8691588640213013\n",
      "step 31: 0.8691588640213013\n",
      "step 32: 0.8691588640213013\n",
      "step 33: 0.8785046339035034\n",
      "step 34: 0.8831775188446045\n",
      "step 35: 0.8831775188446045\n",
      "step 36: 0.8831775188446045\n",
      "step 37: 0.8831775188446045\n",
      "step 38: 0.8831775188446045\n",
      "step 39: 0.8831775188446045\n",
      "step 40: 0.8831775188446045\n",
      "step 41: 0.8831775188446045\n",
      "step 42: 0.8831775188446045\n",
      "step 43: 0.8831775188446045\n",
      "step 44: 0.8831775188446045\n",
      "step 45: 0.8831775188446045\n",
      "step 46: 0.8785046339035034\n",
      "step 47: 0.8785046339035034\n",
      "step 48: 0.8785046339035034\n",
      "step 49: 0.8785046339035034\n",
      "step 50: 0.8785046339035034\n",
      "step 51: 0.8785046339035034\n",
      "step 52: 0.8785046339035034\n",
      "step 53: 0.8785046339035034\n",
      "step 54: 0.8785046339035034\n",
      "step 55: 0.8831775188446045\n",
      "step 56: 0.8831775188446045\n",
      "step 57: 0.8831775188446045\n",
      "step 58: 0.8831775188446045\n",
      "step 59: 0.8831775188446045\n",
      "step 60: 0.8831775188446045\n",
      "step 61: 0.8878504633903503\n",
      "step 62: 0.8925233483314514\n",
      "step 63: 0.8971962332725525\n",
      "step 64: 0.9018691182136536\n",
      "step 65: 0.9018691182136536\n",
      "step 66: 0.9018691182136536\n",
      "step 67: 0.9065420031547546\n",
      "step 68: 0.9065420031547546\n",
      "step 69: 0.9065420031547546\n",
      "step 70: 0.9158878326416016\n",
      "step 71: 0.9158878326416016\n",
      "step 72: 0.9158878326416016\n",
      "step 73: 0.9158878326416016\n",
      "step 74: 0.9158878326416016\n",
      "step 75: 0.9158878326416016\n",
      "step 76: 0.9158878326416016\n",
      "step 77: 0.9158878326416016\n",
      "step 78: 0.9205607175827026\n",
      "step 79: 0.9205607175827026\n",
      "step 80: 0.9205607175827026\n",
      "step 81: 0.9205607175827026\n",
      "step 82: 0.9205607175827026\n",
      "step 83: 0.9252336025238037\n",
      "step 84: 0.9252336025238037\n",
      "step 85: 0.9252336025238037\n",
      "step 86: 0.9252336025238037\n",
      "step 87: 0.9252336025238037\n",
      "step 88: 0.9252336025238037\n",
      "step 89: 0.9252336025238037\n",
      "step 90: 0.9252336025238037\n",
      "step 91: 0.9299064874649048\n",
      "step 92: 0.9299064874649048\n",
      "step 93: 0.9345794320106506\n",
      "step 94: 0.9345794320106506\n",
      "step 95: 0.9345794320106506\n",
      "step 96: 0.9345794320106506\n",
      "step 97: 0.9345794320106506\n",
      "step 98: 0.9345794320106506\n",
      "step 99: 0.9345794320106506\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 100\n",
    "model = Perceptron(lr)\n",
    "for i in range(epochs):\n",
    "    model.train_step(X,y)\n",
    "    print(f'step {i}: {model.score(X,y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Run the training multiple times.  Is the training the same each time, or does it vary?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is different each time because the weights are initialized randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the learning rate and number of epochs to find the best setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.01, epochs: 500, accuracy: 0.9579439163208008\n",
      "LR: 0.01, epochs: 200, accuracy: 0.9579439163208008\n",
      "LR: 0.01, epochs: 1000, accuracy: 0.9579439163208008\n",
      "LR: 0.01, epochs: 50, accuracy: 0.9532709717750549\n",
      "LR: 0.01, epochs: 100, accuracy: 0.9532709717750549\n",
      "LR: 0.001, epochs: 500, accuracy: 0.9532709717750549\n",
      "LR: 0.001, epochs: 1000, accuracy: 0.9532709717750549\n",
      "LR: 0.01, epochs: 25, accuracy: 0.9439252018928528\n",
      "LR: 0.001, epochs: 200, accuracy: 0.9392523169517517\n",
      "LR: 0.0001, epochs: 1000, accuracy: 0.9345794320106506\n",
      "LR: 0.001, epochs: 100, accuracy: 0.9252336025238037\n",
      "LR: 0.001, epochs: 50, accuracy: 0.8831775188446045\n",
      "LR: 0.0001, epochs: 500, accuracy: 0.8831775188446045\n",
      "LR: 1e-05, epochs: 50, accuracy: 0.8644859790802002\n",
      "LR: 1e-05, epochs: 1000, accuracy: 0.8598130345344543\n",
      "LR: 1e-05, epochs: 100, accuracy: 0.8551401495933533\n",
      "LR: 0.001, epochs: 25, accuracy: 0.8551401495933533\n",
      "LR: 0.0001, epochs: 200, accuracy: 0.8551401495933533\n",
      "LR: 1e-05, epochs: 200, accuracy: 0.8364485502243042\n",
      "LR: 0.0001, epochs: 100, accuracy: 0.8364485502243042\n",
      "LR: 1e-05, epochs: 500, accuracy: 0.7850466966629028\n",
      "LR: 1e-05, epochs: 25, accuracy: 0.7663550972938538\n",
      "LR: 0.0001, epochs: 25, accuracy: 0.7663550972938538\n",
      "LR: 0.1, epochs: 25, accuracy: 0.7523364424705505\n",
      "LR: 0.0001, epochs: 50, accuracy: 0.7056074738502502\n",
      "LR: 1, epochs: 500, accuracy: 0.6822429895401001\n",
      "LR: 1, epochs: 50, accuracy: 0.6822429895401001\n",
      "LR: 1, epochs: 25, accuracy: 0.6822429895401001\n",
      "LR: 1, epochs: 200, accuracy: 0.6822429895401001\n",
      "LR: 1, epochs: 1000, accuracy: 0.6822429895401001\n",
      "LR: 1, epochs: 100, accuracy: 0.6822429895401001\n",
      "LR: 0.1, epochs: 500, accuracy: 0.6822429895401001\n",
      "LR: 0.1, epochs: 200, accuracy: 0.6822429895401001\n",
      "LR: 0.1, epochs: 1000, accuracy: 0.6822429895401001\n",
      "LR: 0.1, epochs: 100, accuracy: 0.6822429895401001\n",
      "LR: 0.1, epochs: 50, accuracy: 0.3457943797111511\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "lr_list = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "epochs_list = [25, 50, 100, 200, 500, 1000]\n",
    "results = {}\n",
    "\n",
    "for lr, epochs in itertools.product(lr_list, epochs_list):\n",
    "    model = Perceptron(lr)\n",
    "    for i in range(epochs):\n",
    "        model.train_step(X,y)\n",
    "\n",
    "    accuracy = model.score(X,y)\n",
    "    results[accuracy] = f'LR: {lr}, epochs: {epochs}, accuracy: {accuracy}'\n",
    "\n",
    "results = dict(reversed(sorted(results.items())))\n",
    "for result in results.values():\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result was with 500 epochs and a learning rate of 0.01\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Classification with Tabular Data\n",
    "\n",
    "Cameron Wolff, see bottom for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5OUW75f1w56j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CNAG8fBHw_ns"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('tree_species_classifier_data.npz'):\n",
    "  !wget -O tree_species_classifier_data.npz \"https://www.dropbox.com/scl/fi/b7mw23k3ifaeui9m8nnn3/tree_species_classifier_data.npz?rlkey=bgxp37c1t04i7q35waf3slc26&dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XSnb9owtxT5w"
   },
   "outputs": [],
   "source": [
    "data = np.load('tree_species_classifier_data.npz')\n",
    "train_features = data['train_features']\n",
    "train_labels = data['train_labels']\n",
    "test_features = data['test_features']\n",
    "test_labels = data['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 7, 7, 7], shape=(15707,), dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the data\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  338,  252, ...,  113,  116,  152],\n",
       "       [   0,  453,  339, ...,  120,  117,  150],\n",
       "       [   0,  460,  378, ...,  122,  143,  155],\n",
       "       ...,\n",
       "       [   0,  785,  710, ...,  720,  715,  711],\n",
       "       [   0,  838,  663, ...,  704,  649,  673],\n",
       "       [   0, 1056,  761, ...,  790,  707,  776]],\n",
       "      shape=(15707, 426), dtype=int16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1554,), (1554, 426))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 81., 148.,  62.,   9.,   6.,  17.,  24.,  18.,  48.,  13.]),\n",
       "  array([   0.,  181.,  362.,  543.,  724.,  905., 1086., 1267., 1448.,\n",
       "         1629., 1810.]),\n",
       "  <BarContainer object of 10 artists>),\n",
       " (array([  1.,  55., 138.,  40.,  56.,   6.,   9.,  25.,  49.,  47.]),\n",
       "  array([   0. ,  369.6,  739.2, 1108.8, 1478.4, 1848. , 2217.6, 2587.2,\n",
       "         2956.8, 3326.4, 3696. ]),\n",
       "  <BarContainer object of 10 artists>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_features[0], alpha=0.5), plt.hist(train_features[len(train_features[0])-1], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing\n",
    "pca = sklearn.decomposition.PCA(n_components=32, whiten=True)\n",
    "\n",
    "train_features_reduced = pca.fit_transform(train_features)\n",
    "test_features_reduced = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier accuracy: 0.833976833976834\n",
      "Neural Network Classifier accuracy: 0.797940797940798\n"
     ]
    }
   ],
   "source": [
    "# Classifiers using scikit-learn\n",
    "sklearn_linear = sklearn.linear_model.LogisticRegression()\n",
    "sklearn_linear.fit(train_features_reduced, train_labels)\n",
    "\n",
    "sklearn_nn = sklearn.neural_network.MLPClassifier(\n",
    "    hidden_layer_sizes=(100,), activation='relu', max_iter=1_000)\n",
    "sklearn_nn.fit(train_features_reduced, train_labels)\n",
    "\n",
    "sklearn_linear_accuracy = sklearn.metrics.accuracy_score(\n",
    "    sklearn_linear.predict(test_features_reduced), \n",
    "    test_labels)\n",
    "sklearn_nn_accuracy = sklearn.metrics.accuracy_score(\n",
    "    sklearn_nn.predict(test_features_reduced), \n",
    "    test_labels)\n",
    "\n",
    "print(f'Linear Classifier accuracy: {sklearn_linear_accuracy}')\n",
    "print(f'Neural Network Classifier accuracy: {sklearn_nn_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers using PyTorch\n",
    "\n",
    "# a. Create a TensorDataset and DataLoader with batch size 32, train using random shuffling\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        torch.tensor(train_features_reduced, dtype=torch.float32), \n",
    "        torch.tensor(train_labels, dtype=torch.long)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        torch.tensor(test_features_reduced, dtype=torch.float32), \n",
    "        torch.tensor(test_labels, dtype=torch.long)),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the accuracy of the model\n",
    "def accuracy(model, dataloader: torch.utils.data.DataLoader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    acc = None\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for features_train, labels_train in iter(dataloader):        \n",
    "            z = torch.argmax(model(features_train), dim=1)\n",
    "            correct += (z == labels_train).float().sum()\n",
    "            total += z.shape[0]\n",
    "            \n",
    "        acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the model\n",
    "def train(model, dataloader: torch.utils.data.DataLoader):\n",
    "    lr = 1e-2\n",
    "    weight_decay = 0.001\n",
    "    epochs = 100\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        opt.zero_grad() # zero out the gradients\n",
    "    \n",
    "        features_train, labels_train = next(iter(dataloader)) \n",
    "\n",
    "        z = model(features_train) # compute model outputs\n",
    "        loss = loss_fn(z, labels_train) # compute loss\n",
    "    \n",
    "        loss.backward() # compute gradients\n",
    "    \n",
    "        opt.step() # apply gradients in optimizer step\n",
    "        \n",
    "        print(f'accuracy | train {accuracy(torch_linear, train_dataloader):.4f} | test {accuracy(torch_linear, test_dataloader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier\n",
      "accuracy | train 0.1604 | test 0.1667\n",
      "accuracy | train 0.1622 | test 0.1673\n",
      "accuracy | train 0.1637 | test 0.1692\n",
      "accuracy | train 0.1656 | test 0.1705\n",
      "accuracy | train 0.1674 | test 0.1725\n",
      "accuracy | train 0.1708 | test 0.1744\n",
      "accuracy | train 0.1726 | test 0.1750\n",
      "accuracy | train 0.1744 | test 0.1770\n",
      "accuracy | train 0.1775 | test 0.1776\n",
      "accuracy | train 0.1787 | test 0.1821\n",
      "accuracy | train 0.1808 | test 0.1834\n",
      "accuracy | train 0.1829 | test 0.1840\n",
      "accuracy | train 0.1857 | test 0.1840\n",
      "accuracy | train 0.1872 | test 0.1866\n",
      "accuracy | train 0.1886 | test 0.1892\n",
      "accuracy | train 0.1907 | test 0.1911\n",
      "accuracy | train 0.1927 | test 0.1937\n",
      "accuracy | train 0.1955 | test 0.1963\n",
      "accuracy | train 0.1981 | test 0.1988\n",
      "accuracy | train 0.2004 | test 0.2001\n",
      "accuracy | train 0.2028 | test 0.2027\n",
      "accuracy | train 0.2062 | test 0.2059\n",
      "accuracy | train 0.2094 | test 0.2085\n",
      "accuracy | train 0.2129 | test 0.2111\n",
      "accuracy | train 0.2158 | test 0.2136\n",
      "accuracy | train 0.2184 | test 0.2149\n",
      "accuracy | train 0.2211 | test 0.2169\n",
      "accuracy | train 0.2240 | test 0.2181\n",
      "accuracy | train 0.2265 | test 0.2201\n",
      "accuracy | train 0.2293 | test 0.2239\n",
      "accuracy | train 0.2322 | test 0.2246\n",
      "accuracy | train 0.2348 | test 0.2259\n",
      "accuracy | train 0.2372 | test 0.2291\n",
      "accuracy | train 0.2393 | test 0.2291\n",
      "accuracy | train 0.2419 | test 0.2304\n",
      "accuracy | train 0.2444 | test 0.2342\n",
      "accuracy | train 0.2473 | test 0.2362\n",
      "accuracy | train 0.2497 | test 0.2381\n",
      "accuracy | train 0.2517 | test 0.2394\n",
      "accuracy | train 0.2545 | test 0.2413\n",
      "accuracy | train 0.2568 | test 0.2420\n",
      "accuracy | train 0.2592 | test 0.2439\n",
      "accuracy | train 0.2622 | test 0.2445\n",
      "accuracy | train 0.2647 | test 0.2452\n",
      "accuracy | train 0.2682 | test 0.2452\n",
      "accuracy | train 0.2716 | test 0.2471\n",
      "accuracy | train 0.2741 | test 0.2497\n",
      "accuracy | train 0.2765 | test 0.2510\n",
      "accuracy | train 0.2789 | test 0.2497\n",
      "accuracy | train 0.2819 | test 0.2497\n",
      "accuracy | train 0.2855 | test 0.2516\n",
      "accuracy | train 0.2889 | test 0.2568\n",
      "accuracy | train 0.2919 | test 0.2600\n",
      "accuracy | train 0.2955 | test 0.2632\n",
      "accuracy | train 0.2970 | test 0.2651\n",
      "accuracy | train 0.2988 | test 0.2664\n",
      "accuracy | train 0.3016 | test 0.2690\n",
      "accuracy | train 0.3048 | test 0.2716\n",
      "accuracy | train 0.3078 | test 0.2741\n",
      "accuracy | train 0.3108 | test 0.2819\n",
      "accuracy | train 0.3141 | test 0.2844\n",
      "accuracy | train 0.3173 | test 0.2889\n",
      "accuracy | train 0.3206 | test 0.2921\n",
      "accuracy | train 0.3231 | test 0.2941\n",
      "accuracy | train 0.3260 | test 0.2960\n",
      "accuracy | train 0.3292 | test 0.3031\n",
      "accuracy | train 0.3320 | test 0.3057\n",
      "accuracy | train 0.3360 | test 0.3082\n",
      "accuracy | train 0.3391 | test 0.3108\n",
      "accuracy | train 0.3412 | test 0.3147\n",
      "accuracy | train 0.3429 | test 0.3153\n",
      "accuracy | train 0.3457 | test 0.3166\n",
      "accuracy | train 0.3486 | test 0.3192\n",
      "accuracy | train 0.3519 | test 0.3224\n",
      "accuracy | train 0.3551 | test 0.3237\n",
      "accuracy | train 0.3586 | test 0.3263\n",
      "accuracy | train 0.3612 | test 0.3333\n",
      "accuracy | train 0.3644 | test 0.3366\n",
      "accuracy | train 0.3673 | test 0.3411\n",
      "accuracy | train 0.3710 | test 0.3436\n",
      "accuracy | train 0.3734 | test 0.3468\n",
      "accuracy | train 0.3759 | test 0.3488\n",
      "accuracy | train 0.3790 | test 0.3520\n",
      "accuracy | train 0.3801 | test 0.3559\n",
      "accuracy | train 0.3830 | test 0.3604\n",
      "accuracy | train 0.3862 | test 0.3642\n",
      "accuracy | train 0.3903 | test 0.3681\n",
      "accuracy | train 0.3928 | test 0.3732\n",
      "accuracy | train 0.3961 | test 0.3777\n",
      "accuracy | train 0.3996 | test 0.3822\n",
      "accuracy | train 0.4030 | test 0.3855\n",
      "accuracy | train 0.4066 | test 0.3887\n",
      "accuracy | train 0.4106 | test 0.3893\n",
      "accuracy | train 0.4125 | test 0.3912\n",
      "accuracy | train 0.4162 | test 0.3970\n",
      "accuracy | train 0.4195 | test 0.4009\n",
      "accuracy | train 0.4211 | test 0.4048\n",
      "accuracy | train 0.4242 | test 0.4035\n",
      "accuracy | train 0.4272 | test 0.4131\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "\n",
      "Neural Network Classifier\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n",
      "accuracy | train 0.4293 | test 0.4144\n"
     ]
    }
   ],
   "source": [
    "# train a linear classifier and a neural network\n",
    "torch_linear = torch.nn.Linear(32, 8)\n",
    "\n",
    "# 32 input layer, 100 hidden layer, 2 output layer\n",
    "torch_nn = torch.nn.Sequential(\n",
    "    torch.nn.Linear(32, 100),\n",
    "    torch.nn.SiLU(), \n",
    "    torch.nn.Linear(100, 8),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "print('Linear Classifier')\n",
    "train(torch_linear, train_dataloader)\n",
    "print('\\nNeural Network Classifier')\n",
    "train(torch_nn, train_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "### Code Explanation\n",
    "To solve this problem, I used a conventional approach following the problem's description, sticking to the sklearn toolbox for the first section, then switching to PyTorch and custom written functions for the second. \n",
    "\n",
    "The dataset appeared to have 8 unique labels, so when creating the PyTorch models I specified an output layer of that size.\n",
    "\n",
    "I used the sklearn and pytorch documentation to find specific function definitions. When I wanted more general syntax knowledge on API I was unframiliar with, or when I got stuck trying to determine layers not aligning when training my PyTorch models, I used the Quen2.5-Coder-14B LLM, pulled from hugging face. The model showed me example syntax for the functions, which I heavily tweaked to fit my code, and suggested I make sure my dataset only had 2 classes, which it did not. I chose a SiLu activation function for its improvements over ReLu for PyTorch, but this does not seem to have improved results. \n",
    "\n",
    "### Discussion\n",
    "Training matrix was 15,707x426, test matrix was 1,554x426. The rows are the records or samples of the dataset, which each appears to represent a hyperspectral image of one tree. The columns, or features, appear to represent different spectrum, and range from around 0 to 3,000. There are 8 classes corresponding to the following tree species: White fir, Red fir, Incense cedar, Jeffrey pine, Sugar pine, Black oak, Lodgepole pine, and Dead trees. Classes are provided unevenly, with much more of classes 3 and 7, but classes are distrubuted evenly between training and test data.\n",
    "\n",
    "Both pytorch models appear to not overfit the data, as the training and test accuracy is very low. The scikit learn results, with a higher 1,000 iterations, seem to have converged with a much higher accuracy. The linear model, surprisingly, has a higher accuracy than the more complex neural network."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNabx6sCRInWIIstR96Z5ey",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
